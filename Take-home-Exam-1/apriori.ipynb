{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "MIN_SUPPORT = 0.05\n",
    "MIN_CONFIDENT = 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nData Ingestion:\\n3898 samples, 167 products\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('./data/apriori_data.csv')\n",
    "'''\n",
    "Data Ingestion:\n",
    "3898 samples, 167 products\n",
    "'''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(raw_data):\n",
    "    transactions = []\n",
    "    for i in raw_data.values:\n",
    "        transactions.append(list(*np.where(i==1)))              \n",
    "    return transactions\n",
    "\n",
    "def support_count(transactions, itemsets):\n",
    "    candidate_set = {}\n",
    "    total_transactions = len(transactions)\n",
    "    for itemset in itemsets:    \n",
    "        sup_count = np.sum([1 for transaction in transactions if itemset.issubset(transaction)])\n",
    "        candidate_set[itemset] = sup_count / total_transactions\n",
    "    return candidate_set\n",
    "\n",
    "def filter_candidates(candidate_set, min_support):\n",
    "    filtered_set = {}\n",
    "    for itemset, support in candidate_set.items():\n",
    "        if support >= min_support:\n",
    "            filtered_set[itemset] = support\n",
    "    return filtered_set\n",
    "\n",
    "def generate_candidates_itemsets(filter_set, k_step):\n",
    "    candidate_itemsets = set()\n",
    "    freq_items = list(filter_set.keys())    \n",
    "    # print(f\"Frequent item list {freq_items}\")\n",
    "    for i in range(len(freq_items)):\n",
    "        for j in range(i+1, len(freq_items)):\n",
    "            itemset = freq_items[i].union(freq_items[j])           \n",
    "            if len(itemset)==k_step:\n",
    "                candidate_itemsets.add(itemset)\n",
    "    \n",
    "    return candidate_itemsets\n",
    "\n",
    "def apriori(transactions, min_support, preprocess = True):\n",
    "    # Initial frequent 1-itemsets\n",
    "    if preprocess:\n",
    "        transactions = preprocess_data(transactions)\n",
    "    \n",
    "    itemsets_c1 = set(frozenset([item]) for transaction in transactions for item in transaction)\n",
    "    candidate_set = support_count(transactions, itemsets_c1)\n",
    "    k_step = 2\n",
    "\n",
    "    filter_set = filter_candidates(candidate_set, min_support=min_support)\n",
    "    final_set = filter_set.copy()\n",
    "    \n",
    "    while filter_set:\n",
    "        candidate_itemset = generate_candidates_itemsets(filter_set, k_step)\n",
    "        candidate_set = support_count(transactions, candidate_itemset)\n",
    "        filter_set = filter_candidates(candidate_set, min_support=min_support)\n",
    "        final_set.update(filter_set)\n",
    "        k_step+=1        \n",
    "        \n",
    "    \n",
    "    return final_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions_test = [[1,2,5], [2,4], [2,3], [1,2,4], [1,3], [2,3], [1,3], [1,2,3,5], [1,2,3]]\n",
    "# final = apriori(transactions=transactions_test, min_support=MIN_SUPPORT, preprocess=False)\n",
    "# print(f\"Final support: {final}\")\n",
    "\n",
    "# association = []\n",
    "# for key in final.keys():\n",
    "#     if len(key) == 3:\n",
    "#         association.append(key)\n",
    "# print(f\"Asociation: {association}\")\n",
    "\n",
    "# MIN_SUPPORT = 2/9\n",
    "# MIN_CONFIDENT = 0.5\n",
    "\n",
    "# for itemset in association:\n",
    "# # Generate all possible antecedent and consequent pairs\n",
    "#     for i in range(1, len(itemset)):  # Split itemset into antecedent of size 1, 2\n",
    "#         for antecedent in combinations(itemset, i):\n",
    "#             antecedent = frozenset(antecedent)\n",
    "#             consequent = itemset - antecedent  # Remainder of the itemset as consequent\n",
    "            \n",
    "#             # print(f'antecedent: {antecedent}')\n",
    "#             # print(f'consequent: {consequent}')\n",
    "#             # Calculate confidence\n",
    "#             confidence = final.get(itemset, 0) / final.get(antecedent, 1)\n",
    "\n",
    "#             # Check if confidence meets min_confidence threshold\n",
    "#             if (round(confidence,1)) >= MIN_CONFIDENT:\n",
    "#                 conf = round(confidence,2)\n",
    "#                 print('-'*20)\n",
    "#                 print(f\"Rule {antecedent} => {consequent} is valid with confidence {confidence:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_association = apriori(transactions=raw_data, min_support=MIN_SUPPORT)\n",
    "# final_association\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "association = []\n",
    "for key in final_association.keys():\n",
    "    if len(key) == 3:\n",
    "        association.append(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = {}\n",
    "for itemset in association:\n",
    "# Generate all possible antecedent and consequent pairs\n",
    "    for i in range(1, len(itemset)):  # Split itemset into antecedent of size 1, 2\n",
    "        for antecedent in combinations(itemset, i):\n",
    "            antecedent = frozenset(antecedent)\n",
    "            consequent = itemset - antecedent  # Remainder of the itemset as consequent\n",
    "\n",
    "            # Calculate confidence\n",
    "            confidence = final_association.get(itemset, 0) / final_association.get(antecedent, 1)\n",
    "\n",
    "            # Check if confidence meets min_confidence threshold\n",
    "            if confidence >= MIN_CONFIDENT:       \n",
    "                if confidence not in result_dict:\n",
    "                    result_dict[confidence] = [itemset] \n",
    "                else:\n",
    "                    result_dict[confidence].append(itemset)                \n",
    "                # print(f\"Rule {antecedent} => {consequent} is valid with confidence {confidence:.3f}\")\n",
    "           \n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_data = []\n",
    "# #Generate result file\n",
    "# for confident, itemsets in result_dict.items():\n",
    "#     row = ''\n",
    "#     for itemset in itemsets:\n",
    "#         row = row + '||'\n",
    "#         for i in range(len(itemset)):\n",
    "#             row = row + 'PRODUCT' + str(itemset[i]) + '^'\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
